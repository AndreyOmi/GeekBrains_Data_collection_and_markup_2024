# GeekBrains_Data_collection_and_markup_2024
Курс "Сбор и разметка данных" от GeekBrains образца 2024 года

## Урок 1. Основы клиент-серверного взаимодействия. Парсинг API
1. Ознакомиться с некоторые интересными API. https://docs.ozon.ru/api/seller/ https://developers.google.com/youtube/v3/getting-started https://spoonacular.com/food-api

[Решение задачи 1 для Озон (скриншот)](https://github.com/AndreyOmi/GeekBrains_Data_collection_and_markup_2024/blob/main/Seminar_№1/Изучение%20API%20Озон.JPG)

[Решение задачи 1 для YouTube (скриншот)](https://github.com/AndreyOmi/GeekBrains_Data_collection_and_markup_2024/blob/main/Seminar_№1/Изучение%20API%20Youtube_.JPG)

[Решение задачи 1 для Spoonacular (скриншот)](https://github.com/AndreyOmi/GeekBrains_Data_collection_and_markup_2024/blob/main/Seminar_№1/Изучение%20API%20spoonacular_.JPG)

2. Потренируйтесь делать запросы к API. Выберите публичный API, который вас интересует, и потренируйтесь делать API-запросы с помощью Postman. Поэкспериментируйте с различными типами запросов и попробуйте получить различные типы данных.

[Решение задачи 2 - запрос по автору через API сервиса Open Library](https://github.com/AndreyOmi/GeekBrains_Data_collection_and_markup_2024/blob/main/Seminar_№1/Публичный%20API%20Open%20Library%20Поиск%20по%20автору.JPG)

[Решение задачи 2 - запрос по названию книги через API сервиса Open Library](https://github.com/AndreyOmi/GeekBrains_Data_collection_and_markup_2024/blob/main/Seminar_№1/Публичный%20API%20Open%20Library%20Поиск%20по%20книге.JPG)

3. Сценарий Foursquare
4. Напишите сценарий на языке Python, который предложит пользователю ввести интересующую его категорию (например, кофейни, музеи, парки и т.д.).
5. Используйте API Foursquare для поиска заведений в указанной категории.
6. Получите название заведения, его адрес и рейтинг для каждого из них.
7. Скрипт должен вывести название и адрес и рейтинг каждого заведения в консоль.

[Решение задач 3 - 7](https://github.com/AndreyOmi/GeekBrains_Data_collection_and_markup_2024/blob/main/Seminar_№1/homework_seminar_1_05-03-2024_.ipynb)

## Урок 2. Парсинг HTML. BeautifulSoup
1. Выполнить скрейпинг данных в веб-сайта http://books.toscrape.com/ и извлечь информацию о всех книгах на сайте во всех категориях: название, цену, количество товара в наличии (In stock (19 available)) в формате integer, описание.

[Решение задачи 1 - код в файле .ipynb](https://github.com/AndreyOmi/GeekBrains_Data_collection_and_markup_2024/blob/main/Seminar_№2/homework_seminar_2_08-03-2024.ipynb)

2. Затем сохранить эту информацию в JSON-файле.

[Решение задачи 2 - ссылка на JSON-файл](https://github.com/AndreyOmi/GeekBrains_Data_collection_and_markup_2024/blob/main/Seminar_№2/books_from_books.toscrape.com.json)
   
## Урок 3. Системы управления базами данных MongoDB и Кликхаус в Python
1. Установите MongoDB на локальной машине, а также зарегистрируйтесь в онлайн-сервисе. https://www.mongodb.com/ https://www.mongodb.com/products/compass

[Решение задачи 1 - установленная локальная MongoDB с загруженными данными - скриншот](https://github.com/AndreyOmi/GeekBrains_Data_collection_and_markup_2024/blob/main/Seminar_№3/MongoDB%20с%20загруженными%20данными.JPG)

[Решение задачи 1 - проведенная регистрация в облачном сервисе MongoDB - скриншот](https://github.com/AndreyOmi/GeekBrains_Data_collection_and_markup_2024/blob/main/Seminar_№3/Регистрация%20в%20облачном%20сервисе%20MongoDB.JPG)

3. Загрузите данные который вы получили на предыдущем уроке путем скрейпинга сайта с помощью Buautiful Soup в MongoDB и создайте базу данных и коллекции для их хранения.
4. Поэкспериментируйте с различными методами запросов.

[Решение задач 3 - 4 - код в файле .ipynb](https://github.com/AndreyOmi/GeekBrains_Data_collection_and_markup_2024/blob/main/Seminar_№3/homework_seminar_3_12-03-2024.ipynb)   

5. Зарегистрируйтесь в ClickHouse.
6. Загрузите данные в ClickHouse и создайте таблицу для их хранения.

[Решение задач 5 - 6 - скриншот](https://github.com/AndreyOmi/GeekBrains_Data_collection_and_markup_2024/blob/main/Seminar_№3/Попытка%20работы%20с%20ClickHouse2.JPG)

Вывод о решении задач 5 - 6: загеристрироваться в ClickHouse получилось, но сервис не выдает API keys для доступа к облачному хранилищу из-за политики ограничений для России, поэтому загрузить данные в облачное хранилище невозможно.

## Урок 4. Парсинг HTML. XPath

Выберите веб-сайт с табличными данными, который вас интересует.

Напишите код Python, использующий библиотеку requests для отправки HTTP GET-запроса на сайт и получения HTML-содержимого страницы.

Выполните парсинг содержимого HTML с помощью библиотеки lxml, чтобы извлечь данные из таблицы.

Сохраните извлеченные данные в CSV-файл с помощью модуля csv.

Ваш код должен включать следующее:

Строку агента пользователя в заголовке HTTP-запроса, чтобы имитировать веб-браузер и избежать блокировки сервером.

Выражения XPath для выбора элементов данных таблицы и извлечения их содержимого.

[Решение задачи - код в файле .ipynb](https://github.com/AndreyOmi/GeekBrains_Data_collection_and_markup_2024/blob/main/Seminar_№4/homework_seminar_4_15-03-2024.ipynb)

## Урок 5. Scrapy

Найдите сайт, содержащий интересующий вас список или каталог. Это может быть список книг, фильмов, спортивных команд или что-то еще, что вас заинтересовало.

Создайте новый проект Scrapy и определите нового паука. С помощью атрибута start_urls укажите URL выбранной вами веб-страницы.

Определите метод парсинга для извлечения интересующих вас данных. Используйте селекторы XPath или CSS для навигации по HTML и извлечения данных. Возможно, потребуется извлечь данные с нескольких страниц или перейти по ссылкам на другие страницы.

Сохраните извлеченные данные в структурированном формате. Вы можете использовать оператор yield для возврата данных из паука, которые Scrapy может записать в файл в выбранном вами формате (например, JSON или CSV).

Конечным результатом работы должен быть код Scrapy Spider, а также пример выходных данных. Не забывайте соблюдать правила robots.txt и условия обслуживания веб-сайта, а также ответственно подходите к использованию веб-скрейпинга.

Обработка ошибок для случаев, когда данные не имеют ожидаемого формата.

Комментарии для объяснения цели и логики кода.

Примечание: Пожалуйста, не забывайте соблюдать этические и юридические нормы при веб-скреппинге.

[Решение задачи - код Scrapy Spider в файле .py](https://github.com/AndreyOmi/GeekBrains_Data_collection_and_markup_2024/blob/main/Seminar_№5/books_scraper/books_scraper/spiders/book_spider.py)

[Решение задачи - пример выходных данных в файле .json](https://github.com/AndreyOmi/GeekBrains_Data_collection_and_markup_2024/blob/main/Seminar_№5/books_scraper/books_data_gb_lesson_5.json)


## Урок 8. Работа с данными

1. Скачайте датасет House Prices Kaggle со страницы конкурса (https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data) и сохраните его в том же каталоге, что и ваш скрипт или блокнот Python.

2. Загрузите датасет в pandas DataFrame под названием df.

3. Выполните предварительную обработку данных, выполнив следующие шаги: a. Определите и обработайте отсутствующие значения в датасете. Определите, в каких столбцах есть отсутствующие значения, и решите, как их обработать (например, заполнить средним, медианой или модой, или отбросить столбцы/строки с существенными отсутствующими значениями). b. Проверьте и обработайте любые дублирующиеся строки в датасете. c. Проанализируйте типы данных в каждом столбце и при необходимости преобразуйте их (например, из объектных в числовые типы).

4. Проведите разведочный анализ данных (EDA), ответив на следующие вопросы: a. Каково распределение целевой переменной 'SalePrice'? Есть ли какие-либо выбросы? b. Исследуйте взаимосвязи между целевой переменной и другими характеристиками. Есть ли сильные корреляции? c. Исследуйте распределение и взаимосвязи других важных характеристик, таких как 'OverallQual', 'GrLivArea', 'GarageCars' и т.д. d. Визуализируйте данные, используя соответствующие графики (например, гистограммы, диаграммы рассеяния, квадратные диаграммы), чтобы получить представление о датасете.

5. Выполните проектирование признаков путем реализации следующих преобразований: a. Работайте с категориальными переменными, применяя one-hot encoding или label encoding, в зависимости от характера переменной. b. При необходимости создайте новые характеристики, такие как общая площадь или возраст объекта недвижимости, путем объединения существующих характеристик.

6. Сохраните очищенный и преобразованный набор данных в новый CSV-файл под названием 'cleaned_house_prices.csv'.

[Решение задачи - код в файле .ipynb](https://github.com/AndreyOmi/GeekBrains_Data_collection_and_markup_2024/blob/main/Seminar_№8/homework_seminar_8_29-03-2024.ipynb)

[Решение задачи - преобразованный набор данных в файле .csv](https://github.com/AndreyOmi/GeekBrains_Data_collection_and_markup_2024/blob/main/Seminar_№8/cleaned_house_prices.csv)

## Урок 9. Инструменты разметки наборов данных. Итоговая работа

### Задание 1.<br>
Выберите датасет, который имеет отношение к вашей области интересов или исследований. Датасет должен содержать неструктурированные данные, требующие разметки для решения конкретной задачи, например, анализа настроений или распознавания именованных сущностей.

### Задание 2.<br>
Выполните разметку на основе правил (rule-based labeling) на подмножестве выбранного датасета. Разработайте и реализуйте набор правил или условий, которые позволят автоматически присваивать метки данным на основе определенных шаблонов или критериев.

### Задача 3.<br>
Выполните разметку вручную отдельного подмножества выбранного датасета с помощью выбранного вами инструмента разметки.

### Задача 4.<br>
Объедините данные, размеченные вручную, с данными, размеченными на основе правил. Объедините два подмножества размеченных данных в один набор данных, сохранив при этом соответствующую структуру и целостность.

### Задача 5.<br>
Обучите модель машинного обучения, используя объединенный набор размеченных данных. Разделите датасет на обучающий и тестовый наборы и используйте обучающий набор для обучения модели.

### Задача 6.<br>
Оценить эффективность обученной модели на тестовом датасете. Используйте подходящие метрики оценки. Интерпретируйте результаты и проанализируйте эффективность модели в решении задачи разметки.

[Решение задач 1 - 6 - код в файле .ipynb]()

